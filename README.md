# Large-Economy-Model
# U.S Federal Funds Rate Prediction

## 1. 주제 선정

### 1.1 기준 금리란 ?

- 기준 금리는 중앙은행이 결정하는 이자율로 금융기관이 중앙은행에서 자금을 빌릴 때 적용되는 금리입니다. 이는 경제 전반에 영향을 미치며, 대출과 투자에 직접적인 영향을 줍니다.
- 미국 기준금리는 “Federal Funds Interest Rate”라고 하며 연방공개시장위원회(FOMC)의 정책회의에서 결정됩니다.

### 1.2 왜 기준 금리가 중요한가

- 기준 금리는 경제 전반에 걸쳐 중요한 영향을 미치는 요소입니다. 금리 변동은 **차입 비용**을 조정해 소비와 투자를 촉진하거나 억제하고, **인플레이션**을 통제하며, **환율**과 **국제 자본 흐름**에 영향을 줍니다. 또한, 금융 시장에서 **자산 가격**을 결정하는 중요한 요인이므로, 경제 성장과 안정성에 있어 핵심 역할을 합니다.
- 기준 금리 결정에 주 목적은 경기 조절에 있습니다. 금리 인하를 통해 경기를 부양하거나 금리 인상을 통해 물가를 안정시킵니다. 침체된 경기를 회복시키고 과열된 경기를 진정시켜 경제가 지속적으로 충격 없이 성장할 수 있도록 하는 것이 기준 금리입니다.

### 1.3 왜 미국 기준 금리을 예측하는가

- 미국 달러는 기축통화로서 금리 변화가 세계 자본 흐름과 금융시장에 영향을 미치므로 이를 예측하는 것은 큰 의미가 있습니다.
- 미국은 지구의 패권국으로서 미국의 경제·경기 변화는 전세계의 미치는 영향이 큽니다. 하지만 미국에 의해 영향을 받는 한국 등의 다른 국가들에 비해 비교적 외부로부터 기준 금리 결정에 받는 영향이 작습니다. 실제로 한국과 유럽 등지의 국가들은 미국의 경제 기조에 맞춰 움직이는 경향이 강합니다. 하지만 미국이 기준금리를 결정할 때 주로 고려하는 사항은 물가지수, 실업률 등의 내수 경제입니다.

### 1.4 활용성이 있는가?

- 주가, 채권 등의 자산의 가치 변동을 예측할 수 있습니다. 이를 통해 보다 유리한 투자를 할 수 있고 미래에 발생할 리스크를 피할 수 있습니다.
- 물가, 실업률 등의 변동을 예측하고 시뮬레이션 할 수 있습니다. 기준 금리 변화가 경제 전반에 미치는 영향을 예측하여 적절한 기준 금리(중립 금리)를 결정하는 데에 도움이 될 수 있습니다.
- 미국의 기준 금리 변동은 한국, 유럽 등지에 국가에 기준 금리에도 큰 영향을 끼칩니다. 이를 통해 각 국의 기준금리를 예측하고 더 나아가 글로벌 경제 전반을 예측하는 토대가 될 수 있습니다.

## 2. 데이터 수집 및 준비

### 2.1 데이터 소개

- 기준 금리
    - 미국의 기준 금리인 Fed Funds Rate는 목표 금리(Target Rate)와 실효 금리(Effective Rate)로 구분할 수 있습니다. 목표 금리는 FOMC 회의에서 결정되는 금리이고, 실표 금리는 목표 금리를 기준으로 적용되는 은행들의 콜 금리입니다.
    - 데이터 수집 과정에서 목표 금리의 데이터 양이 실효 금리보다 현저히 적었기 때문에 실효 금리인 Effective Rate 데이터를 수집했습니다.
- 이외 경제 지표
    - 경제 기사 등을 통해 FOMC가 기준금리 결정을 위해 고려하는 경제 지표들을 조사하고 취합하였다.
    - 크게 물가 지표, 고용 지표, 경기 지표로 20여 가지의 경제 지표가 있다.
    - 일부는 명목, 실질(core)로 같은 지표 내에서도 구분된다.
    - 일부는 전년 동월 대비(YoY), 전월 대비(MoM)으로 같은 지표 내에서도 구분된다.
    - 명목, 실질/ 전년비, 전월비를 모두 고려했을 때 약 50여가지의 경제 지표를 수집했다.
- Details
    
    ### 기준 금리
    
    - **미국 : Federal Funds Rate**
        - Target Federal Funds Rate (목표 연방기금금리) : FOMC 결정 기준 금리
            - 데이터가 2008년부터 시작해서 데이터가 너무 적다.
        - Effective Federal Funds Rate (실질 연방기금금리) : 은행의 콜 금리
            - 1954년부터 데이터 있으므로 실질 연방기금금리를 사용하기로 결정.
    
    ### **물가 지표**
    
    - 발표 주체
        - 미국 : 노동 통계국, 상무부 경제분석국,
        - 한국 : 통계청
    - **공통**
        - CPI (소비자 물가지수) : 명목/근원, 전월 대비(MoM)/전년 동월 대비(YoY)
    - **미국**
        - PCE (개인소비지출 물가지수) : 명목/근원, 전월대비(MoM)/**전년동월대비(YoY)**
        - PPI (생산자 물가지수) : PPI Final demand/ Core
    - **한국**
    
    ### **고용 지표**
    
    - 발표 주체
        - 미국 : 노동 통계국 고용보고서, 노동부
        - 한국 : 통계청 경제활동인구조사, 고용노동부
    - **공통**
        - 실업률 (Unemployment rate)
    - **미국**
        - 비농업 고용지수 (Nonfarm Payroll Employment)
        - 평균 시간당 임금 (Average Hourly Earnings) : YoY/MoM
        - 실업수당 청구건수 (Jobless Claims) : 신규/연속
        - JOLTs 채용 공고 (Job Openings)
        - 노동 수요 대비 공급률 (JOLTs 구인·이직 보고서)
    - **한국**
        - 국내 취업자 수
        - 상용근로자 1인당 월 평균 임금 총액
    
    ### **경기 지표**
    
    - 발표 주체
        - 미국 : 노동 통계국, 상무부 경제분석국, 연방준비제도, 미시간 대학교
        - 한국 : 한국은행, 통계청
    - 공통
        - GDP 경제 성장률
        - PMI (제조/서비스업 구매관리자지수) : ISM(미국 대기업 위주), S&P Global(중소기업 포함, 한국 별도 발표)
        - Retail Sales (소매판매 지수) : YoY/MoM
        - 산업 생산 지수 :  YoY/MoM
        - OECD 경기선행지수 : 100 기준선 (이상 : 경기 확장/ 미만 : 경기 수축)
        - 소비자 심리 지수 : 100 기준
    - 미국
        - Citi Economic Surprise Index : 정부가 발표한 실물 경제 지표가 투자자가 기대하는 전망치에 얼마나 부합했는지를 나타낸 지수

### 2.2 데이터 수집 방법

1.  ****미국 연방준비은행이 제공하는 경제 데이터를 수집하고 분석할 수 있는 인터페이스인 FRED API에 가입하여 개인 API key를 발급받았습니다.
    - 미국연방준비은행에서 공식적으로 제공하는 데이터로서 가장 신뢰도가 높다고 판단했습니다.
2. 코드 상으로 각 경제지표 데이터에 접근하기 위해 각 경제지표의 code를 수집했습니다. 
    
    ```python
    code_dic = {'CPI': 'CPIAUCSL', 'coreCPI':'CPILFESL', 'PCE':'PCE', 'corePCE':'PCEPI', 'PPI':'PPIACO', 'PPIfd':'PPIFIS', 'corePPIfd':'PPIFES', 
                'unemployment':'UNRATE', 'Nonfarm':'PAYEMS', 'AHE':'CES0500000003',  'job openings':'JTSJOL',
                'GDP':'A191RL1Q225SBEA', 'retail':'MARTSMPCSM44X72USS', 'industrial production':'INDPRO', 'OECD leading':'USALOLITONOSTSAM','consumer sentiment':'UMCSENT'}
    
    claims_dic = {'initial claims': 'ICSA', 'continued claims':'CCSA'}
    
    IR_code = 'FEDFUNDS'
    ```
    
3. python 기반 라이브러리인 fredpy를 이용하여 각 경제지표 데이터를 수집했습니다.
4. 각 경제 지표들의 전년동월비(YoY)는 fredpy에서 제공하는 apc() 메서드를 통해, 전월비(MoM)은 pct_change() 메서드를 이용해 계산했습니다.

### 2.3 EDA

- FRED API 업데이트 날짜
    
    
    | Name | update_date |
    | --- | --- |
    | CPI | 10th |
    | core CPI | 10th |
    | PCE | 27th |
    | core PCE | 27th |
    | PPI | 11th |
    | PPI final demend | 11th |
    | core PPI final demand | 11th |
    | unemployment | 4th |
    | Nonfarm | 4th |
    | Average Hourly Earnings | 4th |
    | Job Openings | 1st |
    | Real GDP | Quarterly |
    | Advance Retail Sales | 17th |
    | Industrial production | 17th |
    | CLI(OECD leading) for U.S | 10th |
    | Consumer sentiment | 27th |
    | Initial claims | Weekly |
    | Continued claims | Weekly |
    | Federal effective funds rate | 1st |
    
    - 각 데이터가 FRED API에서 업데이트되는 날짜를 조사한 바는 왼쪽에 표와 같습니다.
    - 각 데이터의 ‘date’ 컬럼은 대부분 매월 1일입니다.
    - 하지만 실제로는 각 경제 지표는 각기 다른 날에 발표되고 이러한 이유로 데이터 상 같은 달에 해당하는 데이터들로 기준 금리를 예측할 시 잘못된 예측을 할 수 있습니다. 예를 들면 먼저 발표된 기준 금리를 그 이후에 발표된 경제 지표들로 예측하는 모순이 발생합니다.
    - 표를 보면 매월 1일 기준 금리가 가장 먼저 업데이트 되고 이후에 다른 경제 지표들이 업데이트 됩니다. 그러므로 예측의 대상은 다음 달의 기준 금리 또는 이의 변동값이 되어야 합니다.
    - 월간으로 업데이트 되는 다른 데이터와 다르게 주간으로 업데이트되는 실업청구건수(initial claims, continued claims)는 같은 월에 해당하는 값들을 평균내어 월간으로 변환했습니다.
    
- 결측치 (Missing Values)
    
    
    ![흰색 부분이 결측치입니다. ](https://prod-files-secure.s3.us-west-2.amazonaws.com/97b24de5-5da8-4d69-8d21-889ae3acd9ad/0c7123c9-6d06-4f9c-8760-75a6a50c0cd1/image.png)
    
    흰색 부분이 결측치입니다. 
    
    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/97b24de5-5da8-4d69-8d21-889ae3acd9ad/7a9e0dda-a61d-49c4-81ba-e91197cb209c/image.png)
    
    - 기준 금리를 기준으로 모든 데이터들을 병합했을 때 결측치는 위와 같습니다.
    - 상당한 수의 데이터들이 모델 학습에 적절하지 않은 결측률을 가지고 있다고 볼 수 있습니다.
    - 결측치 처리를 위해 각 컬럼별 결측치가 아닌 데이터의 IQR(사분위수)의 Q2 범위의 기준이 되는 개수를 기준으로 이보다 적은 수의 데이터를 가진 컬럼은 제거하고 나머지 결측치는 행 제거를 했습니다.
        - Q2 범위의 기준은 794 였고, 결측치가 아닌 데이터가 794개 보다 적은 컬럼은 제거했습니다.
        - Q2 범위가 가장 적절한 컬럼 수와 데이터의 균형을 가진다고 판단했습니다.
- 이상치 (Outlier)
    
    ![1 : 정상 데이터의 개수
    -1 : 이상치의 개수](https://prod-files-secure.s3.us-west-2.amazonaws.com/97b24de5-5da8-4d69-8d21-889ae3acd9ad/b86d6327-ea36-41af-a847-b9b983f28a45/image.png)
    
    1 : 정상 데이터의 개수
    -1 : 이상치의 개수
    
    - Isolation Forest 기법으로 이상치를 탐지했을 때 적은 데이터셋 규모에 비해 이상치 비율이 상당히 높았다. 이러한 점을 고려했을 때 이상치를 제거하지않고 스케일링을 통해 이상치를 완화하는 것이 적절하다고 판단하였다.
    - Isolation Forest : 여러 개의 결정 트리로 이상치를 탐지하는 기법으로 차원이 높은 데이터셋에서도 효과적인 이상치 탐지 및 처리할 수 있다. 현재 데이터셋의 변수(컬럼)이 상당히 많아 현재 상황에 적절한 이상치 처리 기법이라고 판단했다.
- 스케일링
    - 보다 정확한 상관 분석을 위해 스케일링을 진행했다.
    - 이상치 제거를 안했기 때문에 이상치의 영향을 최소화하면서 스케일을 조정해주는 Robust Scaler를 이용해 스케일링했다.
    - 주의점 : 스케일링 시 train 데이터만 fit 해야한다. test 데이터를 포함하여 fit을 하면 Cheating의 가능성이 있다. train data에 fit, transform을 하고 test data에는 transform만 해주면 된다.
- 상관 분석 (Correlation)
    
    ![상관 계수 도식화 이미지](https://prod-files-secure.s3.us-west-2.amazonaws.com/97b24de5-5da8-4d69-8d21-889ae3acd9ad/096420b9-ec60-4141-89f3-c9d9cb0f286a/a066ae47-8ef1-4413-9970-fe55f14c2fcf.png)
    
    상관 계수 도식화 이미지
    
    - 기준 금리(next interest rate)를 기준으로 상관 계수를 분석하였다.
    - CPI, PPI 등 물가 지표에 해당하는 지수들이 비교적 높은 상관 계수를 보였다.
    - Nonfarm rate, Industrial producion 등의 고용 지표에 해당하는 일부 지수들도 높은 상관 계수를 보였다.
    - 이에 비해, 경기 지표는 기준 금리를 예측하는 데에 충분한 상관 계수를 가지지 않았다.
    

### 2.4 적용한 전처리 방법 소개

- 결측치 처리
    - IQR
        - IQR(Interquartile Range)은 데이터의 분포를 나타내는 통계적 지표로, 데이터의 중앙 50% 범위를 나타냅니다.
        - 1사분위수(Q1): 데이터의 하위 25%에 해당하는 값.
        - 2사분위수(Q2) : 데이터의 50%에 해당하는 값
        - 3사분위수(Q3): 데이터의 상위 25%에 해당하는 값.
        - 전체 컬럼에서 2사분위수보다 적은 데이터 수를 가진 컬럼을 제거했다.
        
- 이상치 처리
    - Isolation Forest
        - 여러 개의 결정 트리를 통해 이상치를 데이터를 분할하고 격리하여 이상치를 탐지하는 기법으로 이상치는 정상 분포의 데이터보다 더 적은 분할로 겨리될 가능성이 높다는 아이디어에서 시작했다.
        - 특징으로는 차원이 높은 데이터셋에서도 효과적으로 이상치를 탐지한다는 점이다.
        - 50여 가지의 경제지표를 가진 데이터셋을 가진 현재의 상황에서 적절한 이상치 탐지 기법이라고 판단하고 채택했다.
    
- 스케일링
    - Robust Scaler
        - 중앙값을 0으로, IQR(Q3-Q1)을 1로 조정하는 스케일 기법이다.
        - 중앙값과 IQR 사용하기 때문에 이상치의 영향으로 최소화하며 데이터의 스케일을 조정해준다.
        - 데이터셋의 규모가 작기 때문에 이상치를 제거하지 않았기 때문에 이상치의 영향을 최소화하기 위해 여러 스케일링 기법 중 Robust Scaler를 채택했다.
        - 모델의 target으로 들어갈 후보자들은 [interest rate, previous interest rate, next interest rate, previous change, present change] 스케일링하지 않았다.
            - 일반적으로 모델의 y로 들어가는 변수들은 스케일링 하지 않는다.
        
- 상관 관계
    - 기준 금리와의 상관 계수가 0.3 미만인 컬럼들은 모델 학습에 방해가 될거라 판단하여 제거했습니다.
    - 도식화했을 때 개인적으로 가장 보기 편하고 구별이 잘되는 색이라 코드를 넣습니다.
        
        ```python
         # 색깔 조합 파라미터인 cmap 
         sns.heatmap(temp_df.corr(),vmin=-1,vmax=1,annot=True,linewidths=0.2,cmap='RdYlGn', ax=ax)
        ```
        

## 3. 평가지표 설정

### 3.1 평가 지표 설명

- **RMSE**를 성능 개선 방향의 기준으로 설정하였다. 그 이유는 원래 데이터와 같은 단위를 가지기 때문에 해석이 용이하기 때문이다.
- 이 외에도 MAE, MSE, $R^2$의 값도 출력하여 함께 보았다.
- 각 평가 지표에 대한 설명
    
    
    | name | 이름 | 설명 |
    | --- | --- | --- |
    | MAE(Mean Absolute Error) | 평균 절대 오차 | 예측 값과 실제 값의 차이의 절대값을 평균한 값.  MSE보다 이상치에 덜 민감하다. |
    | MSE(Mean Squeared Error) | 평균 제곱 오차 | 예측 값과 실제 값의 차이를 제곱하여 평균한 값. 값이 작을수록 모델의 성능이 좋다**.** |
    | RMSE | 루트 평균 제곱 오차 | MSE의 제곱근으로, 원래 데이터와 같은 단위를 가져서 해석이 편하다. |
    | $R^2$(R-squared) | 결정 계수  | feature들이 y를 얼마만큼 설명해주는 지 가리키는 지표. 1에 가까울수록 좋다. |

## 4. 베이스라인 모델 선정

### 4.1 성능 비교를 위해 기준으로 삼을 basic 모델과 선정 이유

| Model | Linear Regression |
| --- | --- |
| 선정 이유  | - 기초 성능 평가 : 
 다른 복잡한 모델과 비교할 때, 선형 회귀는 기본 성능 기준을 제공하고 이를 통해 복잡한 모델이 실제로 개선된 성능을 보이는지 평가하기 용이하다고 판단했다.

- 과적합 방지 : 
 데이터셋의 규모를 고려했을 때 복잡한 모델에 비해 과적합 위험이 적어 과적합으로 인한 잘못된 평가 점수가 베이스라인으로 설정될 위험을 피할 수 있다고 판단했다.  |
| RMSE 점수 | 0.49605 |
| 이외 점수 | MAE : 0.25865
MSE : 0.24607
R2 : 0.0076 |

### 4.2 교차 검증 (Cross Validation)

- 데이터셋의 작은 규모로 인해 최대한 데이터를 학습에 이용하고자 교차 검증 기법을 적용했다.
- 일반적으로 주로 쓰는 K-Fold cross validation 기법을 사용했다.

## 5. 모델 성능 개선

### 5.1 데이터 핸들링

1. **결측치 다중 대체** 
    - 원천 데이터셋은 기준 금리 데이터 기준 843행을 가진 매우 작은 규모를 가졌고 결측치도 상당히 많다.
    - 그래서 결측치를 최대한 살리면서 모델이 효과적으로 학습시킬 수 있는 방법에 대해 탐구했다.
    - 결과적으로 회귀 대체와 다중 대체를 통한 결측치 대체법을 알게 되었다.
        - 기존의 최빈값, 평균값 등으로 대체하는 방법은 알고있었지만 이러한 방식을 적은 데이터셋에 적용하면 그 신뢰도가 크게 하락하고 모델의 학습에도 나쁜 영향을 끼칠 것이라고 판단하여 사용하지 않았다.
    - 조사한 대체법들 중 가장 성능이 좋다고 판단되는 다중 대체법을 이용하였다.
    - 결측률이 30% 이상인 컬럼들은 제거 후 나머지 결측치들에 대하여 다중 대체하였다.
    - python 기반 mice 라이브러리를 사용했다.
    - 다중 대체법(Multiple Imputation)에 대한 설명
        - 다중 대체법 다음의 과정을 걸친다.
        1. Imputation :  가능한 대체 값의 분포에서 추출된 서로 다른 값으로 결측치를 대체한 복수의 데이터셋을 생성
        2. Analysis : 각 데이터셋에 대한 분석을 수행하고 모수 추정치와 표준오차를 계산
        3. Pooling : 모수 추정치와 표준오차를 통합하여 하나의 분석 결과를 제시
2. **Isolation Forest를 이용한 이상치 제거**
    
    ![800여 개의 데이터 중 4개의 이상치를 탐지했다.](https://prod-files-secure.s3.us-west-2.amazonaws.com/97b24de5-5da8-4d69-8d21-889ae3acd9ad/d06b448d-1713-4f6a-b702-a606ad6112f2/6fec141a-ce79-487b-a79a-1a14fa0d5b53.png)
    
    800여 개의 데이터 중 4개의 이상치를 탐지했다.
    
    - Isolation Forest : 여러 개의 결정 트리로 이상치를 탐지하는 기법으로 차원이 높은 데이터셋에서도 효과적인 이상치 탐지 및 처리할 수 있다.
    - 다중 대체를 통해 데이터의 손실을 줄였기 때문에 이상치를 제거하여 모델의 학습 성능을 높이는 것이 좋다고 판단하여 Isolation Forest 기법을 이용하여 이상치를 탐지·제거했다.
    - 이상치를 탐지하는 기법은 IQR, z-score 기법도 있지만 현재 다소 높은 차원을 가진 데이터셋을 고려했을 때 Isolation Forest 기법이 적절하다고 판단했다.
3. **MinMax Scaler** 
    - 이상치를 제거했기 때문에 Robust Scaler 대신 더 회귀 문제 성능 향상에 도움이 될 MinMax Scaler를 이용하여 features의 스케일을 조정하였다.
    - MinMax Scaler는 이상치에 영향을 많이 받지만 데이터의 범위를 0과 1사이로 조정해주는 정규화 스케일링 기법이다.
4. **다중공선성 처리**
    
    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/97b24de5-5da8-4d69-8d21-889ae3acd9ad/a5638794-eef2-4586-82a3-6a757833b6ab/7af4a178-1340-4d38-99be-7efd280020c8.png)
    
    - 정답을 제외한 변수 간 높은 상관 계수를 가지는 변수들이 많았다.
    - 그 이유는 1. 각 변수들에 전년대비, 전월대비 연산을 적용하여 추가했고 2. 각 변수들이 서로 영향을 주고 받기 때문이라고 해석했다.
    - 다중공선성 처리가 회귀 문제 솔루션에 도움을 주는 지에 대해서는 의견이 갈렸다.
    - 하지만 현재 상황에서는 유사한 의미를 가지는 변수들이 많아 다중공선성 처리가 성능 향상에 도움이 될 것이라고 판단하여 적용하였다.
    - 변수들 간 상관계수가 서로 0.9 이상의 값을 가지는 변수들을 추출했고 이들 중 정답값과 가장 높은 상관계수를 가지는 변수만 남기고 제거했다.

### 5.2 모델 핸들링

- 모델 핸들링은 AutoML을 이용하여 최적의 모델과 하이퍼파라미터를 찾는 방향으로 진행했다.
1. **Optuna**
    - Optuna를 사용할 때에는 범위를 지정해줘야한다. 검토할 ML 모델들의 리스트와, 각 모델 별 파라미터의 범위를 지정해줘야한다.
    - 또한 기준이 되는 평가 지표나 점수를 지정해줘야한다.
    - 지정해준 모델과 파라미터 범위를 검토하고 평가지표 기준 최적의 모델과 파라미터를 찾는 작업을 지정한 Trial만큼 반복한다.
    - Random Forest, XGBoost, LightGBM, CatBoost 등 주로 Bagging 기반 회귀 모델들을 지정해 파라미터 최적화를 진행했다.
    - 하이퍼파라미터에 대해서는 주로 각 모델 별 과대적합에 관여하는 파라미터들의 최적값을 찾는 방향으로 진행했고, 이 외에도 Optuna의 Best Trial 출력을 보며 지정한 범위 끝 부분에 값을 가진 파라미터들을 수정했다.
2. **Autogluon**
    
    ![AutoGluon이 자동으로 수행하여 찾은 모델 및 하이퍼파라미터와 그 성능](https://prod-files-secure.s3.us-west-2.amazonaws.com/97b24de5-5da8-4d69-8d21-889ae3acd9ad/e41d19bb-bdb8-421e-b99b-f2f61b3ed286/image.png)
    
    AutoGluon이 자동으로 수행하여 찾은 모델 및 하이퍼파라미터와 그 성능
    
    - Autogluon을 사용할 때는 모델이나 파라미터 범위를 지정해주지 않아도된다.
    - 데이터셋, 문제 유형(회귀, 분류 등), 평가지표 등을 지정해주면 최적화된 모델과 하이퍼파라미터를 찾아준다.
    - 검토할 각 모델의 하이퍼파라미터에 대해 알아야하는 Optuna에 비해 쉽고 속도도 빨랐다.
3. **Cross validation**
    - Cross validation의 fold 개수, 즉 cv 파라미터의 값을 크게 설정하였을 때 RMSE가 향상되었다.
    - cv 값을 600 정도까지 성능이 향상되었지만 700부터는 성능이 하락했다.

## 6. 결과 분석

### Best Result of Each Model

| Model | RMSE | 비고 |
| --- | --- | --- |
| Linear | 0.4831 | sklearn |
| RandomForest | 0.4782 | optuna |
| XGBoost | 0.4128 | autogluon |
| CatBoost | 0.4159 | autogluon |
| LightGBM | 0.4892 | optuna |
| WeightedEnsemble | 0.4012 | autogluon |

- AutoML의 일종인 autogluon 사용해 찾은 WeightedEnsemble 모델이 RMSE 기준 가장 좋은 성능을 보였다.

### DataHandling (수정 필요)

|  | base | Multiple Imputation | Remove Outlier | MinMaxScaler | Multicollinearity |
| --- | --- | --- | --- | --- | --- |
| Linear | 0.4971 |  |  |  | 0.4831 |
| RandomForest |  | 0.4827 |  | 0.4808 | 0.4777 |
| XGBoost | 0.5149 | 0.4963 |  |  | 0.4128 |
| CatBoost |  | 0.4348 |  |  | 0.4159 |
| LightGBM | 0.4892 |  |  |  |  |
| WeightedEnsemble |  |  |  |  | 0.4012 |

### 6.1 성능 향상 이유 분석

1. **결측치 다중대체**
    - 정보 활용 극대화 : 작은 데이터셋에서 결측치가 모델 성능에 미치는 영향이 크기 때문에, 단순히 결측치를 제거했을 때보다 다중대체를 통해 가능한 많은 정보를 모델이 학습할 수 있었다.
    - 편향 감소 : 결측치를 제거할 경우 데이터의 대표성이 저하되는데, 다양한 대체값을 생성하여 데이터의 편향을 줄였다.
    - 모델 일반화 능력 향상 : 여러 대체값을 생성함으로써 데이터셋의 다양성을 높였고, 이에 따라 모델의 일반화 능력이 향상되었다.
2. **이상치 제거**
    - 해석 용이성 : 이상치를 제거함으로써 상관 관계 등의 EDA 해석이 명확해져, 인사이트를 도출하는 데 도움이 되었다.
    - 데이터 분포 개선 : 이상치를 제거함으로써 이상치에 민감하지만 회귀 문제 예측에 도움이 되는 스케일링 기법을 사용할 수 있었다.
    - 과적합 감소 : 모델의 파라미터가 더 안정적으로 추정되어, 과적합이 개선되었다.
3. **다중공선성 처리**
    - 불필요한 특징 제거 : 전년대비, 전월대비 등 파생된 변수나 다른 변수에 영향을 받는 변수들 중 정답(기준 금리)와 상관 계수가 비교적 낮은 변수들을 제거함으로써 과적합을 감소시키고 계산 안정성이 증가되었다.
4. **AutoGluon을 통한 모델 및 하이퍼파라미터 최적화**
    - 시간 절약 : 모델 선택 및 하이퍼파라미터 튜닝을 자동으로 수행하여, 시간을 절약할 수 있었다.
    - 사용 용이성 : 여러 머신러닝 모델과 그 하이퍼파라미터에 대한 지식이 없어도 쉽게 사용할 수 있었다

### 6.2 성능 하락 이유 분석

1. y(label)을 기준 금리(Interest rate)에서 그 변동치(다음 달 기준금리 - 이번 달 기준금리)으로 변경 
    - 타겟 변수를 기준 금리에서 금리 변동치로 변경했을 때 RMSE 점수는 비슷했지만, 단위의 차이로 인해 실질적인 성능은 하락했다고 해석했다.

## 7. 향후 발전 계획

- MLOps 연습 겸 데이터수집 및 처리 및 웹사이트 구현
    - back-end : FastAPI
    - Docker
    - Jenkins
